{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226c986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import http.client, urllib.parse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3389569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDist(houses, locations):\n",
    "    \n",
    "    min_dist = 999999999\n",
    "    \n",
    "    for house in houses:\n",
    "        x1 = house['latitude']\n",
    "        x2 = house['longitude']\n",
    "        for location in locations:\n",
    "            x2 = location['latitude']\n",
    "            y2 = location['longitude']\n",
    "            dist = (math.sqrt((x2 - x1)**2 + (y2 - y1)**2))*100\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                \n",
    "        distances.append(min_dist)  \n",
    "    \n",
    "    return distances\n",
    "\n",
    "def getCoords(df):\n",
    "    \n",
    "    #api info\n",
    "    conn = http.client.HTTPConnection('api.positionstack.com')\n",
    "    key = 'df3b33e27a0f6451fd9aae993c6a26fa'\n",
    "    \n",
    "    \n",
    "    def query(coord, address):\n",
    "\n",
    "        params = urllib.parse.urlencode({\n",
    "            'access_key': key,\n",
    "            'query': address,\n",
    "            'limit': 1\n",
    "            })\n",
    "        \n",
    "        conn.request('GET', '/v1/forward?{}'.format(params))\n",
    "        results = conn.getresponse()\n",
    "        data = json.loads(results.read())['data'][0] #converts json to dict\n",
    "        \n",
    "        if coord == 'x':\n",
    "            result = data['latitude']\n",
    "        else:\n",
    "            result = data['longitude']\n",
    "        \n",
    "        return result\n",
    "    \n",
    "\n",
    "    lat = [query('x', address) for address in df.iloc[:,0]]\n",
    "    lon = [query('y', address) for address in df.iloc[:,0]]\n",
    "    \n",
    "    df['latitude'] = lat\n",
    "    df['longitude'] = lon\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b0828e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'subset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#IMPORT AND ORGANIZE DATA\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#get coordinates when necessary\u001b[39;00m\n\u001b[0;32m      4\u001b[0m houses \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/houses_clean.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m houses_la \u001b[38;5;241m=\u001b[39m \u001b[43mhouses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubset\u001b[49m(houses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLos Angeles\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mtolower())\n\u001b[0;32m      7\u001b[0m houses_anaheim \u001b[38;5;241m=\u001b[39m houses\u001b[38;5;241m.\u001b[39msubset(houses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnaheim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m houses_longbeach \u001b[38;5;241m=\u001b[39m houses\u001b[38;5;241m.\u001b[39msubset(houses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLong Beach\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'subset'"
     ]
    }
   ],
   "source": [
    "#IMPORT AND ORGANIZE DATA\n",
    "#get coordinates when necessary\n",
    "\n",
    "houses = pd.read_csv('../data/houses_clean.csv')\n",
    "\n",
    "houses_la = houses.subset(houses['City'] == 'Los Angeles'.tolower())\n",
    "houses_anaheim = houses.subset(houses['City'] == 'Anaheim')\n",
    "houses_longbeach = houses.subset(houses['City'] == 'Long Beach')\n",
    "\n",
    "houses_dallas = houses.subset(houses['City'] == 'Dallas')\n",
    "houses_fortworth = houses.subset(houses['City'] == 'Fort Worth')\n",
    "houses_arlington_tx = houses.subset(houses['City'] == 'Arlington' and houses['State'] == 'TX')\n",
    "\n",
    "houses_chicago = houses.subset(houses['City'] == 'Chicago')\n",
    "houses_naperville = houses.subset(houses['City'] == 'Naperville')\n",
    "houses_elgin = houses.subset(houses['City'] == 'Elgin')\n",
    "\n",
    "houses_washington = houses.subset(houses['City'] == 'Washington')\n",
    "houses_alexandria = houses.subset(houses['City'] == 'Alexandria')\n",
    "houses_arlington_va = houses.subset(houses['City'] == 'Arlington' and houses['State'] == 'VA')\n",
    "\n",
    "\n",
    "schools = pd.read_csv('/data/schools_clean.cvs')\n",
    "schools = getCoords(schools)\n",
    "schools_la = schools.subset(schools['City'] == 'Los Angeles'.tolower())\n",
    "schools_anaheim = schools.subset(schools['City'] == 'Anaheim')\n",
    "schools_longbeach = schools.subset(schools['City'] == 'Long Beach')\n",
    "\n",
    "schools_dallas = schools.subset(schools['City'] == 'Dallas')\n",
    "schools_fortworth = schools.subset(schools['City'] == 'Fort Worth')\n",
    "schools_arlington_tx = schools.subset(schools['City'] == 'Arlington' and schools['State'] == 'TX')\n",
    "\n",
    "schools_chicago = schools.subset(schools['City'] == 'Chicago')\n",
    "schools_naperville = schools.subset(schools['City'] == 'Naperville')\n",
    "schools_elgin = schools.subset(schools['City'] == 'Elgin')\n",
    "\n",
    "schools_washington = schools.subset(schools['City'] == 'Washington')\n",
    "schools_alexandria = schools.subset(schools['City'] == 'Alexandria')\n",
    "schools_arlington_va = schools.subset(schools['City'] == 'Arlington' and schools['State'] == 'VA')\n",
    "\n",
    "\n",
    "other = pd.read_csv('..data/other_locations_clean.csv')\n",
    "other = getCoords(other)\n",
    "hospitals_la = other.subset(other['City'] == 'Los Angeles')['hospital']\n",
    "hospitals_lb = other.subset(other['City'] == 'Long Beach')['hospital']\n",
    "hospitals_a = other.subset(other['City'] == 'Anaheim')['hospital']\n",
    "\n",
    "hospitals_d = other.subset(other['City'] == 'Dallas')['hospital']\n",
    "hospitals_atx = other.subset(other['City'] == 'ArlingtonTX')['hospital']\n",
    "hospitals_fw = other.subset(other['City'] == 'Fort Worth')['hospital']\n",
    "\n",
    "hospitals_c = other.subset(other['City'] == 'Chicago')['hospital']\n",
    "hospitals_e = other.subset(other['City'] == 'Elgin')['hospital']\n",
    "hospitals_n = other.subset(other['City'] == 'Naperville')['hospital']\n",
    "\n",
    "hospitals_dc = other.subset(other['City'] == 'Washington')['hospital']\n",
    "hospitals_ava = other.subset(other['City'] == 'ArlingtonVA')['hospital']\n",
    "hospitals_alex = other.subset(other['City'] == 'Alexandria')['hospital']\n",
    "\n",
    "grocery_la = other.subset(other['City'] == 'Los Angeles')['grocery']\n",
    "grocery_lb = other.subset(other['City'] == 'Long Beach')['grocery']\n",
    "grocery_a = other.subset(other['City'] == 'Anaheim')['grocery']\n",
    "\n",
    "grocery_d = other.subset(other['City'] == 'Dallas')['grocery']\n",
    "grocery_atx = other.subset(other['City'] == 'ArlingtonTX')['grocery']\n",
    "grocery_fw = other.subset(other['City'] == 'Fort Worth')['grocery']\n",
    "\n",
    "grocery_c = other.subset(other['City'] == 'Chicago')['grocery']\n",
    "grocery_e = other.subset(other['City'] == 'Elgin')['grocery']\n",
    "grocery_n = other.subset(other['City'] == 'Naperville')['grocery']\n",
    "\n",
    "grocery_dc = other.subset(other['City'] == 'Washington')['grocery']\n",
    "grocery_ava = other.subset(other['City'] == 'ArlingtonVA')['grocery']\n",
    "grocery_alex = other.subset(other['City'] == 'Alexandria')['grocery']\n",
    "\n",
    "gym_la = other.subset(other['City'] == 'Los Angeles')['gym']\n",
    "gym_lb = other.subset(other['City'] == 'Long Beach')['gym']\n",
    "gym_a = other.subset(other['City'] == 'Anaheim')['gym']\n",
    "\n",
    "gym_d = other.subset(other['City'] == 'Dallas')['gym']\n",
    "gym_atx = other.subset(other['City'] == 'ArlingtonTX')['gym']\n",
    "gym_fw = other.subset(other['City'] == 'Fort Worth')['gym']\n",
    "\n",
    "gym_c = other.subset(other['City'] == 'Chicago')['gym']\n",
    "gym_e = other.subset(other['City'] == 'Elgin')['gym']\n",
    "gym_n = other.subset(other['City'] == 'Naperville')['gym']\n",
    "\n",
    "gym_dc = other.subset(other['City'] == 'Washington')['gym']\n",
    "gym_ava = other.subset(other['City'] == 'ArlingtonVA')['gym']\n",
    "gym_alex = other.subset(other['City'] == 'Alexandria')['gym']\n",
    "\n",
    "parks_la = other.subset(other['City'] == 'Los Angeles')['parks']\n",
    "parks_lb = other.subset(other['City'] == 'Long Beach')['parks']\n",
    "parks_a = other.subset(other['City'] == 'Anaheim')['parks']\n",
    "\n",
    "parks_d = other.subset(other['City'] == 'Dallas')['parks']\n",
    "parks_atx = other.subset(other['City'] == 'ArlingtonTX')['parks']\n",
    "parks_fw = other.subset(other['City'] == 'Fort Worth')['parks']\n",
    "\n",
    "parks_c = other.subset(other['City'] == 'Chicago')['parks']\n",
    "parks_e = other.subset(other['City'] == 'Elgin')['parks']\n",
    "parks_n = other.subset(other['City'] == 'Naperville')['parks']\n",
    "\n",
    "parks_dc = other.subset(other['City'] == 'Washington')['parks']\n",
    "parks_ava = other.subset(other['City'] == 'ArlingtonVA')['parks']\n",
    "parks_alex = other.subset(other['City'] == 'Alexandria')['parks']\n",
    "\n",
    "beaches_la = other.subset(other['City'] == 'Los Angeles')['beaches']\n",
    "beaches_lb = other.subset(other['City'] == 'Long Beach')['beaches']\n",
    "beaches_a = other.subset(other['City'] == 'Anaheim')['beaches']\n",
    "\n",
    "beaches_d = other.subset(other['City'] == 'Dallas')['beaches']\n",
    "beaches_atx = other.subset(other['City'] == 'ArlingtonTX')['beaches']\n",
    "beaches_fw = other.subset(other['City'] == 'Fort Worth')['beaches']\n",
    "\n",
    "beaches_c = other.subset(other['City'] == 'Chicago')['beaches']\n",
    "beaches_e = other.subset(other['City'] == 'Elgin')['beaches']\n",
    "beaches_n = other.subset(other['City'] == 'Naperville')['beaches']\n",
    "\n",
    "beaches_dc = other.subset(other['City'] == 'Washington')['beaches']\n",
    "beaches_ava = other.subset(other['City'] == 'ArlingtonVA')['beaches']\n",
    "beaches_alex = other.subset(other['City'] == 'Alexandria')['beaches']\n",
    "\n",
    "cemetary_la = other.subset(other['City'] == 'Los Angeles')['cemetary']\n",
    "cemetary_lb = other.subset(other['City'] == 'Long Beach')['cemetary']\n",
    "cemetary_a = other.subset(other['City'] == 'Anaheim')['cemetary']\n",
    "\n",
    "cemetary_d = other.subset(other['City'] == 'Dallas')['cemetary']\n",
    "cemetary_atx = other.subset(other['City'] == 'ArlingtonTX')['cemetary']\n",
    "cemetary_fw = other.subset(other['City'] == 'Fort Worth')['cemetary']\n",
    "\n",
    "cemetary_c = other.subset(other['City'] == 'Chicago')['cemetary']\n",
    "cemetary_e = other.subset(other['City'] == 'Elgin')['cemetary']\n",
    "cemetary_n = other.subset(other['City'] == 'Naperville')['cemetary']\n",
    "\n",
    "cemetary_dc = other.subset(other['City'] == 'Washington')['cemetary']\n",
    "cemetary_ava = other.subset(other['City'] == 'ArlingtonVA')['cemetary']\n",
    "cemetary_alex = other.subset(other['City'] == 'Alexandria')['cemetary']\n",
    "\n",
    "shopping_la = other.subset(other['City'] == 'Los Angeles')['shopping']\n",
    "shopping_lb = other.subset(other['City'] == 'Long Beach')['shopping']\n",
    "shopping_a = other.subset(other['City'] == 'Anaheim')['shopping']\n",
    "\n",
    "shopping_d = other.subset(other['City'] == 'Dallas')['shopping']\n",
    "shopping_atx = other.subset(other['City'] == 'ArlingtonTX')['shopping']\n",
    "shopping_fw = other.subset(other['City'] == 'Fort Worth')['shopping']\n",
    "\n",
    "shopping_c = other.subset(other['City'] == 'Chicago')['shopping']\n",
    "shopping_e = other.subset(other['City'] == 'Elgin')['shopping']\n",
    "shopping_n = other.subset(other['City'] == 'Naperville')['shopping']\n",
    "\n",
    "shopping_dc = other.subset(other['City'] == 'Washington')['shopping']\n",
    "shopping_ava = other.subset(other['City'] == 'ArlingtonVA')['shopping']\n",
    "shopping_alex = other.subset(other['City'] == 'Alexandria')['shopping']\n",
    "\n",
    "resturant_la = other.subset(other['City'] == 'Los Angeles')['resturant']\n",
    "resturant_lb = other.subset(other['City'] == 'Long Beach')['resturant']\n",
    "resturant_a = other.subset(other['City'] == 'Anaheim')['resturant']\n",
    "\n",
    "resturant_d = other.subset(other['City'] == 'Dallas')['resturant']\n",
    "resturant_atx = other.subset(other['City'] == 'ArlingtonTX')['resturant']\n",
    "resturant_fw = other.subset(other['City'] == 'Fort Worth')['resturant']\n",
    "\n",
    "resturant_c = other.subset(other['City'] == 'Chicago')['resturant']\n",
    "resturant_e = other.subset(other['City'] == 'Elgin')['resturant']\n",
    "resturant_n = other.subset(other['City'] == 'Naperville')['resturant']\n",
    "\n",
    "resturant_dc = other.subset(other['City'] == 'Washington')['resturant']\n",
    "resturant_ava = other.subset(other['City'] == 'ArlingtonVA')['resturant']\n",
    "resturant_alex = other.subset(other['City'] == 'Alexandria')['resturant']\n",
    "\n",
    "golf_la = other.subset(other['City'] == 'Los Angeles')['golf']\n",
    "golf_lb = other.subset(other['City'] == 'Long Beach')['golf']\n",
    "golf_a = other.subset(other['City'] == 'Anaheim')['golf']\n",
    "\n",
    "golf_d = other.subset(other['City'] == 'Dallas')['golf']\n",
    "golf_atx = other.subset(other['City'] == 'ArlingtonTX')['golf']\n",
    "golf_fw = other.subset(other['City'] == 'Fort Worth')['golf']\n",
    "\n",
    "golf_c = other.subset(other['City'] == 'Chicago')['golf']\n",
    "golf_e = other.subset(other['City'] == 'Elgin')['golf']\n",
    "golf_n = other.subset(other['City'] == 'Naperville')['golf']\n",
    "\n",
    "golf_dc = other.subset(other['City'] == 'Washington')['golf']\n",
    "golf_ava = other.subset(other['City'] == 'ArlingtonVA')['golf']\n",
    "golf_alex = other.subset(other['City'] == 'Alexandria')['golf']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c39560d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = pd.read_csv('../data/other_locations_clean.csv')\n",
    "\n",
    "houses_la = houses.loc[houses['City'] == 'Anaheim']\n",
    "houses_anaheim = houses.loc[houses['City'] == 'Los Angeles']\n",
    "houses_longbeach = houses.loc[houses['City'] == 'Long Beach']\n",
    "\n",
    "houses_dallas = houses.loc[houses['City'] == 'Dallas']\n",
    "houses_fortworth = houses.loc[houses['City'] == 'Fort Worth']\n",
    "houses_arlington_tx = houses.loc[houses['City'] == 'ArlingtonTX']\n",
    "\n",
    "houses_chicago = houses.loc[houses['City'] == 'Chicago']\n",
    "houses_naperville = houses.loc[houses['City'] == 'Naperville']\n",
    "houses_elgin = houses.loc[houses['City'] == 'Elgin']\n",
    "\n",
    "houses_washington = houses.loc[houses['City'] == 'Washington']\n",
    "houses_alexandria = houses.loc[houses['City'] == 'Alexandria']\n",
    "houses_arlington_va = houses.loc[houses['City'] == 'ArlingtonVA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43db7cec",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Price'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Jeff\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Jeff\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Jeff\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Price'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [36], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m houses_il \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([houses_chicago, houses_naperville, houses_elgin])\n\u001b[0;32m      9\u001b[0m \u001b[39m#convert prices into numpy arrays\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m price_ca \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(houses_ca[\u001b[39m'\u001b[39;49m\u001b[39mPrice\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     11\u001b[0m price_tx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(houses_tx[\u001b[39m'\u001b[39m\u001b[39mPrice\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     12\u001b[0m price_dc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(houses_dc[\u001b[39m'\u001b[39m\u001b[39mPrice\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Jeff\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Jeff\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Price'"
     ]
    }
   ],
   "source": [
    "#NORMALIZE HOUSE PRICES ACCORDING TO REGION\n",
    "\n",
    "#combine cities into metro areas\n",
    "houses_ca = pd.concat([houses_la, houses_anaheim, houses_longbeach])\n",
    "houses_tx = pd.concat([houses_dallas, houses_fortworth, houses_arlington_tx])\n",
    "houses_dc = pd.concat([houses_washington, houses_alexandria, houses_arlington_va])\n",
    "houses_il = pd.concat([houses_chicago, houses_naperville, houses_elgin])\n",
    "\n",
    "#convert prices into numpy arrays\n",
    "price_ca = np.array(houses_ca['Price'])\n",
    "price_tx = np.array(houses_tx['Price'])\n",
    "price_dc = np.array(houses_dc['Price'])\n",
    "price_il = np.array(houses_il['Price'])\n",
    "\n",
    "#normalize\n",
    "price_ca = preprocessing.normalize([price_ca])\n",
    "price_tx = preprocessing.normalize([price_tx])\n",
    "price_dc = preprocessing.normalize([price_dc])\n",
    "price_il = preprocessing.normalize([price_il])\n",
    "\n",
    "#replace prices back into their respective dataframes\n",
    "houses_ca['Price'] = price_ca\n",
    "houses_tx['Price'] = price_tx\n",
    "houses_dc['Price'] = price_dc\n",
    "houses_il['Price'] = price_il\n",
    "\n",
    "#subset so that all city dataframes have the normalized price values\n",
    "houses_la = houses_ca.subset(houses['City'] == 'Los Angeles'.tolower())\n",
    "houses_anaheim = houses_ca.subset(houses['City'] == 'Anaheim')\n",
    "houses_longbeach = houses_ca.subset(houses['City'] == 'Long Beach')\n",
    "\n",
    "houses_dallas = houses_tx.subset(houses['City'] == 'Dallas')\n",
    "houses_fortworth = houses_tx.subset(houses['City'] == 'Fort Worth')\n",
    "houses_arlington_tx = houses_tx.subset(houses['City'] == 'Arlington' and houses['State'] == 'TX')\n",
    "\n",
    "houses_chicago = houses_il.subset(houses['City'] == 'Chicago')\n",
    "houses_naperville = houses_il.subset(houses['City'] == 'Naperville')\n",
    "houses_elgin = houses_il.subset(houses['City'] == 'Elgin')\n",
    "\n",
    "houses_washington = houses_arlington_va.subset(houses['City'] == 'Washington')\n",
    "houses_alexandria = houses_arlington_va.subset(houses['City'] == 'Alexandria')\n",
    "houses_arlington_va = houses_arlington_va.subset(houses['City'] == 'Arlington' and houses['State'] == 'VA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3afd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADJUST HOUSE PRICES BY SQUARE FOOTAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET DISTANCES\n",
    "\n",
    "houses_la['dist_hospitals'] = getDist(houses_la, hositals_la)\n",
    "#...\n",
    "\n",
    "houses_dallas['dist_gyms'] = getDist(houses_dallas, gyms_dallas)\n",
    "#..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf39fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PERFORM ANALYSIS USING DISTANCES AS VARIABLES TO PREDICT PRICE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
