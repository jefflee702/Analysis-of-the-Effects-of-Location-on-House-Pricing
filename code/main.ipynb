{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2714c114",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m preprocessing\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhttp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparse\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import http.client, urllib.parse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "377c5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDist(houses, locations):\n",
    "    distances = []\n",
    "        \n",
    "    for ind in houses.index:\n",
    "        y1 = houses['Latitude'][ind]\n",
    "        x1 = houses['Longitude'][ind]\n",
    "        min_dist = 9999999\n",
    "        for i in locations.index:\n",
    "            y2 = locations['Latitude'][i]\n",
    "            x2 = locations['Longitude'][i]\n",
    "            try:\n",
    "                dist = (math.sqrt((x2 - x1)**2 + (y2 - y1)**2))*100\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "            except:\n",
    "                pass\n",
    "        distances.append(min_dist)  \n",
    "\n",
    "        \n",
    "    return distances\n",
    "\n",
    "def getCoords(df):\n",
    "    \n",
    "    #api info\n",
    "    conn = http.client.HTTPConnection('api.positionstack.com')\n",
    "    key = 'df3b33e27a0f6451fd9aae993c6a26fa'\n",
    "    \n",
    "    \n",
    "    def query(coord, address):\n",
    "\n",
    "        params = urllib.parse.urlencode({\n",
    "            'access_key': key,\n",
    "            'query': address,\n",
    "            'limit': 1\n",
    "            })\n",
    "        \n",
    "        conn.request('GET', '/v1/forward?{}'.format(params))\n",
    "        results = conn.getresponse()\n",
    "        data = json.loads(results.read())['data'][0] #converts json to dict\n",
    "        \n",
    "        if coord == 'x':\n",
    "            result = data['latitude']\n",
    "        else:\n",
    "            result = data['longitude']\n",
    "            \n",
    "            return result\n",
    "    \n",
    "\n",
    "    lat = [query('x', address) for address in df.iloc[:,0]]\n",
    "    lon = [query('y', address) for address in df.iloc[:,0]]\n",
    "    \n",
    "    df['latitude'] = lat\n",
    "    df['longitude'] = lon\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d6248b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT AND ORGANIZE DATA\n",
    "\n",
    "houses = pd.read_csv('../data/final/houses_clean.csv')\n",
    "\n",
    "houses_la = houses[houses['City'] == 'Los Angeles']\n",
    "houses_anaheim = houses[houses['City'] == 'Anaheim']\n",
    "houses_longbeach = houses[houses['City'] == 'Long Beach']\n",
    "\n",
    "houses_dallas = houses[houses['City'] == 'Dallas']\n",
    "houses_fortworth = houses[houses['City'] == 'Fort Worth']\n",
    "houses_arlington_tx = houses[houses['City'] == 'ArlingtonTX']\n",
    "\n",
    "houses_chicago = houses[houses['City'] == 'Chicago']\n",
    "houses_naperville = houses[houses['City'] == 'Naperville']\n",
    "houses_elgin = houses[houses['City'] == 'Elgin']\n",
    "\n",
    "houses_washington = houses[houses['City'] == 'Washington']\n",
    "houses_alexandria = houses[houses['City'] == 'Alexandria']\n",
    "houses_arlington_va = houses[houses['City'] == 'ArlingtonVA']\n",
    "\n",
    "\n",
    "schools = pd.read_csv('../data/final/schools.csv')\n",
    "schools_la = schools[schools['City'] == 'Los Angeles']\n",
    "schools_anaheim = schools[schools['City'] == 'Anaheim']\n",
    "schools_longbeach = schools[schools['City'] == 'Long Beach']\n",
    "\n",
    "schools_dallas = schools[schools['City'] == 'Dallas']\n",
    "schools_fortworth = schools[schools['City'] == 'Fort Worth']\n",
    "schools_atx = schools[schools['City'] == 'ArlingtonTX']\n",
    "\n",
    "schools_chicago = schools[schools['City'] == 'Chicago']\n",
    "schools_naperville = schools[schools['City'] == 'Naperville']\n",
    "schools_elgin = schools[schools['City'] == 'Elgin']\n",
    "\n",
    "schools_washington = schools[schools['City'] == 'Washington']\n",
    "schools_alex = schools[schools['City'] == 'Alexandria']\n",
    "schools_ava = schools[schools['City'] == 'ArlingtonVA']\n",
    "\n",
    "\n",
    "hospitals = pd.read_csv('../data/final/hospital.csv')\n",
    "\n",
    "hospitals_la = hospitals[hospitals['City'] == 'Los Angeles']\n",
    "hospitals_a = hospitals[hospitals['City'] == 'Anaheim']\n",
    "hospitals_lb = hospitals[hospitals['City'] == 'Long Beach']\n",
    "\n",
    "hospitals_d = hospitals[hospitals['City'] == 'Dallas']\n",
    "hospitals_fw = hospitals[hospitals['City'] == 'Fort Worth']\n",
    "hospitals_atx = hospitals[hospitals['City'] == 'ArlingtonTX']\n",
    "\n",
    "hospitals_c = hospitals[hospitals['City'] == 'Chicago']\n",
    "hospitals_n = hospitals[hospitals['City'] == 'Naperville']\n",
    "hospitals_e = hospitals[hospitals['City'] == 'Elgin']\n",
    "\n",
    "hospitals_dc = schools[schools['City'] == 'Washington']\n",
    "hospitals_alex = schools[schools['City'] == 'Alexandria']\n",
    "hospitals_ava = schools[schools['City'] == 'ArlingtonVA']\n",
    "\n",
    "grocery = pd.read_csv('../data/final/grocery.csv')\n",
    "\n",
    "grocery_la = grocery[grocery['City'] == 'Los Angeles']\n",
    "grocery_a = grocery[grocery['City'] == 'Anaheim']\n",
    "grocery_lb = grocery[grocery['City'] == 'Long Beach']\n",
    "\n",
    "grocery_d = grocery[grocery['City'] == 'Dallas']\n",
    "grocery_fw = grocery[grocery['City'] == 'Fort Worth']\n",
    "grocery_atx = grocery[grocery['City'] == 'ArlingtonTX']\n",
    "\n",
    "grocery_c = grocery[grocery['City'] == 'Chicago']\n",
    "grocery_n = grocery[grocery['City'] == 'Naperville']\n",
    "grocery_e = grocery[grocery['City'] == 'Elgin']\n",
    "\n",
    "grocery_dc = grocery[grocery['City'] == 'Washington']\n",
    "grocery_alex = grocery[grocery['City'] == 'Alexandria']\n",
    "grocery_ava = grocery[grocery['City'] == 'ArlingtonVA']\n",
    "\n",
    "gym = pd.read_csv('../data/final/gym.csv')\n",
    "\n",
    "gym_la = gym[gym['City'] == 'Los Angeles']\n",
    "gym_lb = gym[gym['City'] == 'Long Beach']\n",
    "gym_a = gym[gym['City'] == 'Anaheim']\n",
    "\n",
    "gym_d = gym[gym['City'] == 'Dallas']\n",
    "gym_atx = gym[gym['City'] == 'ArlingtonTX']\n",
    "gym_fw = gym[gym['City'] == 'Fort Worth']\n",
    "\n",
    "gym_c = gym[gym['City'] == 'Chicago']\n",
    "gym_e = gym[gym['City'] == 'Elgin']\n",
    "gym_n = gym[gym['City'] == 'Naperville']\n",
    "\n",
    "gym_dc = gym[gym['City'] == 'Washington']\n",
    "gym_ava = gym[gym['City'] == 'ArlingtonVA']\n",
    "gym_alex = gym[gym['City'] == 'Alexandria']\n",
    "\n",
    "parks = pd.read_csv('../data/final/parks.csv')\n",
    "\n",
    "parks_la = parks[parks['City'] == 'Los Angeles']\n",
    "parks_lb = parks[parks['City'] == 'Long Beach']\n",
    "parks_a = parks[parks['City'] == 'Anaheim']\n",
    "\n",
    "parks_d = parks[parks['City'] == 'Dallas']\n",
    "parks_atx = parks[parks['City'] == 'ArlingtonTX']\n",
    "parks_fw = parks[parks['City'] == 'Fort Worth']\n",
    "\n",
    "parks_c = parks[parks['City'] == 'Chicago']\n",
    "parks_e = parks[parks['City'] == 'Elgin']\n",
    "parks_n = parks[parks['City'] == 'Naperville']\n",
    "\n",
    "parks_dc = parks[parks['City'] == 'Washington']\n",
    "parks_ava = parks[parks['City'] == 'ArlingtonVA']\n",
    "parks_alex = parks[parks['City'] == 'Alexandria']\n",
    "\n",
    "beaches = pd.read_csv('../data/final/beach.csv')\n",
    "\n",
    "beaches_la = beaches[beaches['City'] == 'Los Angeles']\n",
    "beaches_lb = beaches[beaches['City'] == 'Long Beach']\n",
    "beaches_a = beaches[beaches['City'] == 'Anaheim']\n",
    "\n",
    "beaches_d = beaches[beaches['City'] == 'Dallas']\n",
    "beaches_atx = beaches[beaches['City'] == 'ArlingtonTX']\n",
    "beaches_fw = beaches[beaches['City'] == 'Fort Worth']\n",
    "\n",
    "beaches_c = beaches[beaches['City'] == 'Chicago']\n",
    "beaches_e = beaches[beaches['City'] == 'Elgin']\n",
    "beaches_n = beaches[beaches['City'] == 'Naperville']\n",
    "\n",
    "beaches_dc = beaches[beaches['City'] == 'Washington']\n",
    "beaches_ava = beaches[beaches['City'] == 'ArlingtonVA']\n",
    "beaches_alex = beaches[beaches['City'] == 'Alexandria']\n",
    "\n",
    "cemetary = pd.read_csv('../data/final/cemetary.csv')\n",
    "\n",
    "cemetary_la = cemetary[cemetary['City'] == 'Los Angeles']\n",
    "cemetary_lb = cemetary[cemetary['City'] == 'Long Beach']\n",
    "cemetary_a = cemetary[cemetary['City'] == 'Anaheim']\n",
    "\n",
    "cemetary_d = cemetary[cemetary['City'] == 'Dallas']\n",
    "cemetary_atx = cemetary[cemetary['City'] == 'ArlingtonTX']\n",
    "cemetary_fw = cemetary[cemetary['City'] == 'Fort Worth']\n",
    "\n",
    "cemetary_c = cemetary[cemetary['City'] == 'Chicago']\n",
    "cemetary_e = cemetary[cemetary['City'] == 'Elgin']\n",
    "cemetary_n = cemetary[cemetary['City'] == 'Naperville']\n",
    "\n",
    "cemetary_dc = cemetary[cemetary['City'] == 'Washington']\n",
    "cemetary_ava = cemetary[cemetary['City'] == 'ArlingtonVA']\n",
    "cemetary_alex = cemetary[cemetary['City'] == 'Alexandria']\n",
    "\n",
    "shopping = pd.read_csv('../data/final/shopping.csv')\n",
    "\n",
    "shopping_la = shopping[shopping['City'] == 'Los Angeles']\n",
    "shopping_lb = shopping[shopping['City'] == 'Long Beach']\n",
    "shopping_a = shopping[shopping['City'] == 'Anaheim']\n",
    "\n",
    "shopping_d = shopping[shopping['City'] == 'Dallas']\n",
    "shopping_atx = shopping[shopping['City'] == 'ArlingtonTX']\n",
    "shopping_fw = shopping[shopping['City'] == 'Fort Worth']\n",
    "\n",
    "shopping_c = shopping[shopping['City'] == 'Chicago']\n",
    "shopping_e = shopping[shopping['City'] == 'Elgin']\n",
    "shopping_n = shopping[shopping['City'] == 'Naperville']\n",
    "\n",
    "shopping_dc = shopping[shopping['City'] == 'Washington']\n",
    "shopping_ava = shopping[shopping['City'] == 'ArlingtonVA']\n",
    "shopping_alex = shopping[shopping['City'] == 'Alexandria']\n",
    "\n",
    "resturant = pd.read_csv('../data/final/restaurants.csv')\n",
    "\n",
    "resturant_la = resturant[resturant['City'] == 'Los Angeles']\n",
    "resturant_lb = resturant[resturant['City'] == 'Long Beach']\n",
    "resturant_a = resturant[resturant['City'] == 'Anaheim']\n",
    "\n",
    "resturant_d = resturant[resturant['City'] == 'Dallas']\n",
    "resturant_atx = resturant[resturant['City'] == 'ArlingtonTX']\n",
    "resturant_fw = resturant[resturant['City'] == 'Fort Worth']\n",
    "\n",
    "resturant_c = resturant[resturant['City'] == 'Chicago']\n",
    "resturant_e = resturant[resturant['City'] == 'Elgin']\n",
    "resturant_n = resturant[resturant['City'] == 'Naperville']\n",
    "\n",
    "resturant_dc = resturant[resturant['City'] == 'Washington']\n",
    "resturant_ava = resturant[resturant['City'] == 'ArlingtonVA']\n",
    "resturant_alex = resturant[resturant['City'] == 'Alexandria']\n",
    "\n",
    "golf = pd.read_csv('../data/final/golf.csv')\n",
    "\n",
    "golf_la = golf[golf['City'] == 'Los Angeles']\n",
    "golf_lb = golf[golf['City'] == 'Long Beach']\n",
    "golf_a = golf[golf['City'] == 'Anaheim']\n",
    "\n",
    "golf_d = golf[golf['City'] == 'Dallas']\n",
    "golf_atx = golf[golf['City'] == 'ArlingtonTX']\n",
    "golf_fw = golf[golf['City'] == 'Fort Worth']\n",
    "\n",
    "golf_c = golf[golf['City'] == 'Chicago']\n",
    "golf_e = golf[golf['City'] == 'Elgin']\n",
    "golf_n = golf[golf['City'] == 'Naperville']\n",
    "\n",
    "golf_dc = golf[golf['City'] == 'Washington']\n",
    "golf_ava = golf[golf['City'] == 'ArlingtonVA']\n",
    "golf_alex = golf[golf['City'] == 'Alexandria']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fea00131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize houses for pricing\n",
    "houses = pd.read_csv('../data/houses_clean.csv')\n",
    "\n",
    "houses_la = houses.loc[houses['City'] == 'Anaheim']\n",
    "houses_anaheim = houses.loc[houses['City'] == 'Los Angeles']\n",
    "houses_longbeach = houses.loc[houses['City'] == 'Long Beach']\n",
    "\n",
    "houses_dallas = houses.loc[houses['City'] == 'Dallas']\n",
    "houses_fortworth = houses.loc[houses['City'] == 'Fort Worth']\n",
    "houses_arlington_tx = houses.loc[houses['City'] == 'ArlingtonTX']\n",
    "\n",
    "houses_chicago = houses.loc[houses['City'] == 'Chicago']\n",
    "houses_naperville = houses.loc[houses['City'] == 'Naperville']\n",
    "houses_elgin = houses.loc[houses['City'] == 'Elgin']\n",
    "\n",
    "houses_washington = houses.loc[houses['City'] == 'Washington']\n",
    "houses_alexandria = houses.loc[houses['City'] == 'Alexandria']\n",
    "houses_arlington_va = houses.loc[houses['City'] == 'ArlingtonVA']\n",
    "\n",
    "#combine cities by state\n",
    "houses_ca = pd.concat([houses_la, houses_anaheim, houses_longbeach])\n",
    "houses_tx = pd.concat([houses_dallas, houses_fortworth, houses_arlington_tx])\n",
    "houses_dc = pd.concat([houses_washington, houses_alexandria, houses_arlington_va])\n",
    "houses_il = pd.concat([houses_chicago, houses_naperville, houses_elgin])\n",
    "\n",
    "#divide price by sq ft\n",
    "houses_ca['Housing Price/SQ Ft'] = houses_ca['Housing Price']/houses_ca['SQ Ft']\n",
    "houses_tx['Housing Price/SQ Ft'] = houses_tx['Housing Price']/houses_tx['SQ Ft']\n",
    "houses_dc['Housing Price/SQ Ft'] = houses_dc['Housing Price']/houses_dc['SQ Ft']\n",
    "houses_il['Housing Price/SQ Ft'] = houses_il['Housing Price']/houses_il['SQ Ft']\n",
    "\n",
    "#add column\n",
    "houses_ca['Housing Price/SQ Ft'] = pd.DataFrame(houses_ca['Housing Price/SQ Ft'])\n",
    "houses_tx['Housing Price/SQ Ft'] = pd.DataFrame(houses_tx['Housing Price/SQ Ft'])\n",
    "houses_dc['Housing Price/SQ Ft'] = pd.DataFrame(houses_dc['Housing Price/SQ Ft'])\n",
    "houses_il['Housing Price/SQ Ft'] = pd.DataFrame(houses_il['Housing Price/SQ Ft'])\n",
    "\n",
    "#normalize\n",
    "houses_ca['Norm Price'] = preprocessing.MinMaxScaler().fit_transform(np.array(houses_ca['Housing Price/SQ Ft']).reshape(-1,1))\n",
    "houses_tx['Norm Price'] = preprocessing.MinMaxScaler().fit_transform(np.array(houses_tx['Housing Price/SQ Ft']).reshape(-1,1))\n",
    "houses_dc['Norm Price'] = preprocessing.MinMaxScaler().fit_transform(np.array(houses_dc['Housing Price/SQ Ft']).reshape(-1,1))\n",
    "houses_il['Norm Price'] = preprocessing.MinMaxScaler().fit_transform(np.array(houses_il['Housing Price/SQ Ft']).reshape(-1,1))\n",
    "\n",
    "#subset so that all city dataframes have the normalized price values\n",
    "houses_la = houses_ca.loc[houses_ca['City'] == 'Anaheim']\n",
    "houses_anaheim = houses_ca.loc[houses_ca['City'] == 'Los Angeles']\n",
    "houses_longbeach = houses_ca.loc[houses_ca['City'] == 'Long Beach']\n",
    "\n",
    "houses_dallas = houses_tx.loc[houses_tx['City'] == 'Dallas']\n",
    "houses_fortworth = houses_tx.loc[houses_tx['City'] == 'Fort Worth']\n",
    "houses_arlington_tx = houses_tx.loc[houses_tx['City'] == 'ArlingtonTX']\n",
    "\n",
    "houses_chicago = houses_il.loc[houses_il['City'] == 'Chicago']\n",
    "houses_naperville = houses_il.loc[houses_il['City'] == 'Naperville'] #not in\n",
    "houses_elgin = houses_il.loc[houses_il['City'] == 'Elgin']\n",
    "\n",
    "houses_washington = houses_dc.loc[houses_dc['City'] == 'Washington']\n",
    "houses_alexandria = houses_dc.loc[houses_dc['City'] == 'Alexandria']\n",
    "houses_arlington_va = houses_dc.loc[houses_dc['City'] == 'ArlingtonVA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e554e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALIZE HOUSE PRICES ACCORDING TO REGION\n",
    "\n",
    "#combine cities into metro areas\n",
    "houses_ca = pd.concat([houses_la, houses_anaheim, houses_longbeach])\n",
    "houses_tx = pd.concat([houses_dallas, houses_fortworth, houses_arlington_tx])\n",
    "houses_dc = pd.concat([houses_washington, houses_alexandria, houses_arlington_va])\n",
    "houses_il = pd.concat([houses_chicago, houses_naperville, houses_elgin])\n",
    "\n",
    "#convert prices into numpy arrays\n",
    "price_ca = np.array(houses_ca['Housing Price'])\n",
    "price_tx = np.array(houses_tx['Housing Price'])\n",
    "price_dc = np.array(houses_dc['Housing Price'])\n",
    "price_il = np.array(houses_il['Housing Price'])\n",
    "\n",
    "#normalize\n",
    "price_ca = preprocessing.normalize([price_ca])\n",
    "price_tx = preprocessing.normalize([price_tx])\n",
    "price_dc = preprocessing.normalize([price_dc])\n",
    "price_il = preprocessing.normalize([price_il])\n",
    "\n",
    "#replace prices back into their respective dataframes\n",
    "houses_ca['Housing Price'] = price_ca[0]\n",
    "houses_tx['Housing Price'] = price_tx[0]\n",
    "houses_dc['Housing Price'] = price_dc[0]\n",
    "houses_il['Housing Price'] = price_il[0]\n",
    "\n",
    "#subset so that all city dataframes have the normalized price values\n",
    "houses_la = houses_ca[houses_ca['City'] == 'Los Angeles']\n",
    "houses_anaheim = houses_ca[houses_ca['City'] == 'Anaheim']\n",
    "houses_longbeach = houses_ca[houses_ca['City'] == 'Long Beach']\n",
    "\n",
    "houses_dallas = houses_tx[houses_tx['City'] == 'Dallas']\n",
    "houses_fortworth = houses_tx[houses_tx['City'] == 'Fort Worth']\n",
    "houses_arlington_tx = houses_tx[houses_tx['City'] == 'ArlingtonTX']\n",
    "\n",
    "houses_chicago = houses_il[houses_il['City'] == 'Chicago']\n",
    "houses_naperville = houses_il[houses_il['City'] == 'Naperville']\n",
    "houses_elgin = houses_il[houses_il['City'] == 'Elgin']\n",
    "\n",
    "houses_washington = houses_dc[houses_dc['City'] == 'Washington']\n",
    "houses_alexandria = houses_dc[houses_dc['City'] == 'Alexandria']\n",
    "houses_arlington_va = houses_dc[houses_dc['City'] == 'ArlingtonVA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "46df46aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [188], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m school_ca \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([schools_la, schools_longbeach, schools_anaheim])\n\u001b[0;32m     14\u001b[0m houses_ca[\u001b[39m'\u001b[39m\u001b[39mdist_hospitals\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m getDist(houses_ca, hospitals_ca)\n\u001b[1;32m---> 15\u001b[0m houses_ca[\u001b[39m'\u001b[39m\u001b[39mdist_gym\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m getDist(houses_ca, gym_ca)\n\u001b[0;32m     16\u001b[0m houses_ca[\u001b[39m'\u001b[39m\u001b[39mdist_cemetary\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m getDist(houses_ca, cemetary_ca)\n\u001b[0;32m     17\u001b[0m houses_ca[\u001b[39m'\u001b[39m\u001b[39mdist_parks\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m getDist(houses_ca, parks_ca)\n",
      "Cell \u001b[1;32mIn [184], line 9\u001b[0m, in \u001b[0;36mgetDist\u001b[1;34m(houses, locations)\u001b[0m\n\u001b[0;32m      7\u001b[0m min_dist \u001b[39m=\u001b[39m \u001b[39m9999999\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m locations\u001b[39m.\u001b[39mindex:\n\u001b[1;32m----> 9\u001b[0m     y2 \u001b[39m=\u001b[39m locations[\u001b[39m'\u001b[39;49m\u001b[39mLatitude\u001b[39;49m\u001b[39m'\u001b[39;49m][i]\n\u001b[0;32m     10\u001b[0m     x2 \u001b[39m=\u001b[39m locations[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m][i]\n\u001b[0;32m     11\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jeff\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:967\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m--> 967\u001b[0m     check_deprecated_indexers(key)\n\u001b[0;32m    968\u001b[0m     key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m)\n\u001b[0;32m    970\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mEllipsis\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jeff\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:2660\u001b[0m, in \u001b[0;36mcheck_deprecated_indexers\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m   2656\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_deprecated_indexers\u001b[39m(key) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2657\u001b[0m     \u001b[39m\"\"\"Checks if the key is a deprecated indexer.\"\"\"\u001b[39;00m\n\u001b[0;32m   2658\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2659\u001b[0m         \u001b[39misinstance\u001b[39m(key, \u001b[39mset\u001b[39m)\n\u001b[1;32m-> 2660\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39;49m(key, \u001b[39mtuple\u001b[39m)\n\u001b[0;32m   2661\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mset\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m key)\n\u001b[0;32m   2662\u001b[0m     ):\n\u001b[0;32m   2663\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2664\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPassing a set as an indexer is deprecated and will raise in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2665\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39ma future version. Use a list instead.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2666\u001b[0m             \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m   2667\u001b[0m             stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   2668\u001b[0m         )\n\u001b[0;32m   2669\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2670\u001b[0m         \u001b[39misinstance\u001b[39m(key, \u001b[39mdict\u001b[39m)\n\u001b[0;32m   2671\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m)\n\u001b[0;32m   2672\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m key)\n\u001b[0;32m   2673\u001b[0m     ):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LA DATA\n",
    "hospitals_ca = pd.concat([hospitals_la, hospitals_lb, hospitals_a])\n",
    "gym_ca = pd.concat([gym_la, gym_lb, gym_a])\n",
    "cemetary_ca = pd.concat([cemetary_la, cemetary_lb, cemetary_a])\n",
    "parks_ca = pd.concat([parks_la, parks_lb, parks_la])\n",
    "beaches_ca = pd.concat([beaches_la, beaches_lb, beaches_a])\n",
    "shopping_ca = pd.concat([shopping_la, shopping_lb, shopping_a])\n",
    "grocery_ca = pd.concat([grocery_la, grocery_lb, grocery_a])\n",
    "resturant_ca = pd.concat([resturant_la, resturant_lb, resturant_a])\n",
    "golf_ca = pd.concat([golf_la, golf_lb, golf_a])\n",
    "school_ca = pd.concat([schools_la, schools_longbeach, schools_anaheim])\n",
    "\n",
    "\n",
    "houses_ca['dist_hospitals'] = getDist(houses_ca, hospitals_ca)\n",
    "houses_ca['dist_gym'] = getDist(houses_ca, gym_ca)\n",
    "houses_ca['dist_cemetary'] = getDist(houses_ca, cemetary_ca)\n",
    "houses_ca['dist_parks'] = getDist(houses_ca, parks_ca)\n",
    "houses_ca['dist_beaches'] = getDist(houses_ca, beaches_ca)\n",
    "houses_ca['dist_shopping'] = getDist(houses_ca, shopping_ca)\n",
    "houses_ca['dist_grocery'] = getDist(houses_ca, grocery_ca)\n",
    "houses_ca['dist_resturant'] = getDist(houses_ca, resturant_ca)\n",
    "houses_ca['dist_golf'] = getDist(houses_ca, golf_ca)\n",
    "houses_ca['dist_school'] = getDist(houses_ca, school_ca)\n",
    "\n",
    "houses_ca = houses_ca.iloc[: , 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca4d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHICAGO DATA\n",
    "hospitals_il = pd.concat([hospitals_c, hospitals_e, hospitals_n])\n",
    "gym_il = pd.concat([gym_c, gym_e, gym_n])\n",
    "cemetary_il = pd.concat([cemetary_c, cemetary_e, cemetary_n])\n",
    "parks_il = pd.concat([parks_c, parks_e, parks_n])\n",
    "beaches_il = pd.concat([beaches_c, beaches_e, beaches_n])\n",
    "shopping_il = pd.concat([shopping_c, shopping_e, shopping_n])\n",
    "grocery_il = pd.concat([grocery_c, grocery_e, grocery_n])\n",
    "resturant_il = pd.concat([resturant_c, resturant_e, resturant_n])\n",
    "golf_il = pd.concat([golf_c, golf_e, golf_n])\n",
    "school_il = pd.concat([schools_chicago, schools_elgin, schools_naperville])\n",
    "\n",
    "\n",
    "houses_il['dist_hospitals'] = getDist(houses_il, hospitals_il)\n",
    "houses_il['dist_gym'] = getDist(houses_il, gym_il)\n",
    "houses_il['dist_cemetary'] = getDist(houses_il, cemetary_il)\n",
    "houses_il['dist_parks'] = getDist(houses_il, parks_il)\n",
    "houses_il['dist_beaches'] = getDist(houses_il, beaches_il)\n",
    "houses_il['dist_shopping'] = getDist(houses_il, shopping_il)\n",
    "houses_il['dist_grocery'] = getDist(houses_il, grocery_il)\n",
    "houses_il['dist_resturant'] = getDist(houses_il, resturant_il)\n",
    "houses_il['dist_golf'] = getDist(houses_il, golf_il)\n",
    "houses_il['dist_school'] = getDist(houses_il, school_il)\n",
    "\n",
    "houses_il = houses_il.iloc[: , 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bfada30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dallas - texas\n",
    "hospitals_tx = pd.concat([hospitals_d, hospitals_fw, hospitals_atx])\n",
    "gym_tx = pd.concat([gym_d, gym_fw, gym_atx])\n",
    "cemetary_tx = pd.concat([cemetary_d, cemetary_fw, cemetary_atx])\n",
    "parks_tx = pd.concat([parks_d, parks_fw, parks_atx])\n",
    "beaches_tx = pd.concat([beaches_d, beaches_fw, beaches_atx])\n",
    "shopping_tx = pd.concat([shopping_d, shopping_fw, shopping_atx])\n",
    "grocery_tx = pd.concat([grocery_d, grocery_fw, grocery_atx])\n",
    "resturant_tx = pd.concat([resturant_d, resturant_fw, resturant_atx])\n",
    "golf_tx = pd.concat([golf_d, golf_fw, golf_atx])\n",
    "school_tx = pd.concat([schools_dallas, schools_fortworth, schools_atx])\n",
    "\n",
    "\n",
    "houses_tx['dist_hospitals'] = getDist(houses_tx, hospitals_tx)\n",
    "houses_tx['dist_gym'] = getDist(houses_tx, gym_tx)\n",
    "houses_tx['dist_cemetary'] = getDist(houses_tx, cemetary_tx)\n",
    "houses_tx['dist_parks'] = getDist(houses_tx, parks_tx)\n",
    "houses_tx['dist_beaches'] = getDist(houses_tx, beaches_tx)\n",
    "houses_tx['dist_shopping'] = getDist(houses_tx, shopping_tx)\n",
    "houses_tx['dist_grocery'] = getDist(houses_tx, grocery_tx)\n",
    "houses_tx['dist_resturant'] = getDist(houses_tx, resturant_tx)\n",
    "houses_tx['dist_golf'] = getDist(houses_tx, golf_tx)\n",
    "houses_tx['dist_school'] = getDist(houses_tx, school_tx)\n",
    "\n",
    "houses_tx = houses_tx.iloc[: , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "414996ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#washington - dc\n",
    "hospitals_dc = pd.concat([hospitals_dc, hospitals_ava, hospitals_alex])\n",
    "gym_dc = pd.concat([gym_dc, gym_ava, gym_alex])\n",
    "cemetary_dc = pd.concat([cemetary_dc, cemetary_ava, cemetary_alex])\n",
    "parks_dc = pd.concat([parks_dc, parks_ava, parks_alex])\n",
    "beaches_dc = pd.concat([beaches_dc, beaches_ava, beaches_alex])\n",
    "shopping_dca = pd.concat([shopping_dc, shopping_ava, shopping_alex])\n",
    "grocery_dc = pd.concat([grocery_dc, grocery_ava, grocery_alex])\n",
    "resturant_dc = pd.concat([resturant_dc, resturant_ava, resturant_alex])\n",
    "golf_dc = pd.concat([golf_dc, golf_ava, golf_alex])\n",
    "school_dc = pd.concat([schools_washington, schools_ava, schools_alex])\n",
    "\n",
    "\n",
    "houses_dc['dist_hospitals'] = getDist(houses_dc, hospitals_dc)\n",
    "houses_dc['dist_gym'] = getDist(houses_dc, gym_dc)\n",
    "houses_dc['dist_cemetary'] = getDist(houses_dc, cemetary_dc)\n",
    "houses_dc['dist_parks'] = getDist(houses_dc, parks_dc)\n",
    "houses_dc['dist_beaches'] = getDist(houses_dc, beaches_dc)\n",
    "houses_dc['dist_shopping'] = getDist(houses_dc, shopping_dc)\n",
    "houses_dc['dist_grocery'] = getDist(houses_dc, grocery_dc)\n",
    "houses_dc['dist_resturant'] = getDist(houses_dc, resturant_dc)\n",
    "houses_dc['dist_golf'] = getDist(houses_dc, golf_dc)\n",
    "houses_dc['dist_school'] = getDist(houses_dc, school_dc)\n",
    "\n",
    "houses_dc = houses_dc.iloc[: , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "76d7bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turned data to csv, put into final data\n",
    "\n",
    "#houses_ca.to_csv(\"final_lametro.csv\")\n",
    "#houses_il.to_csv(\"final_chimetro.csv\")\n",
    "#houses_tx.to_csv(\"final_txmetro.csv\")\n",
    "#houses_dc.to_csv(\"final_dcmetro.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e4a38a8137c1a4cb4c7901223266b1dfbc056b248676f3e6576fa0f54bd3eb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
